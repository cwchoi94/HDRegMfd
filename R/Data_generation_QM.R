


#' @title Generate a list of manifold-valued covariates for quantile regression.
#' 
#' @description
#' Generate a list of manifold-valued covariates for quantile regression.
#' 
#' @param n the number of data points.
#' @param Xspaces a \eqn{p} vector specifying the underlying spaces of \eqn{X_j}.
#' @param Xmu.list a \eqn{p} list of the Frechet means of \eqn{X_j}.
#' @param Xdims a \eqn{p} vector specifying the dimensions of \eqn{X_j}.
#' @param Xrho a correlation parameter ranging from -1 to 1, with a default value of 0.5.
#' @param Xsigma a common standard deviation parameter, with a default value of 1.
#' @param a a parameter such that \eqn{\text{Var}(\xi_{jk})\asymp k^{-2a}}.
#' 
#' @return a list of data containing:
#'    \describe{
#'       \item{j}{a \eqn{p}-list of generated data, where each \eqn{j}th element is an \eqn{n\times D_j} matrix.}
#'       \item{Xspaces}{a \eqn{p} vector specifying the underlying spaces of \eqn{X_j}, see \code{\link{Check.manifold}}.}
#'       \item{p}{the number of \eqn{X_j}.}
#' }
QM.covariates.generate = function(n,Xspaces,Xmu.list,Xdims,Xrho=0.5,Xsigma=1,a=1){
  # compute intrinsic dimension
  p = length(Xdims)
  Xdims_ = sapply(1:p,function(i){
    if(Xspaces[i] %in% c('simplex','sphere')){
      Xdims[i]-1
    }else if (Xspaces[i]=='SPD.LogEuclid'){
      (Xdims[i]+sqrt(Xdims[i]))/2
    }else{
      Xdims[i]
    }})
  Xdims.max = max(Xdims_)
  
  # generate scores
  Zeta = lapply(1:p,function(j){covariates.generate.real(n,Xdims.max,0,Xsigma)})
  Xi = lapply(1:p,function(j){
    if (j==1){
      Xi.each = Zeta[[j]] + Xrho * Zeta[[j+1]]
    } else if (j==p){
      Xi.each = Zeta[[j]] + Xrho * Zeta[[j-1]]
    } else{
      Xi.each = Zeta[[j]] + Xrho * (Zeta[[j-1]] + Zeta[[j+1]])
    }
    if (Xspaces[j]=='Wasserstein'){
      Xi.each = (2*pnorm(Xi.each) - 1)/sqrt(2)
    }
    return(Xi.each[,1:Xdims_[j],drop=FALSE])
  })
  
  Xi.scaled = lapply(1:p,function(j){Transform.Xi(Xi[[j]],Xspaces[j],a)})
  
  # generate X_j
  X = lapply(1:p,function(j){covariates.generate.each(Xi.scaled[[j]],Xmu.list[[j]],Xspaces[j])})
  X[['spaces']] = Xspaces
  X[['p']] = p
  
  Xdata = list(X=X,Xi=Xi,Xi.scaled=Xi.scaled,Xmu.list=Xmu.list)
  return(Xdata)
}





#' @title Generate a random error \eqn{\varepsilon} under quantile linear regression settings
#' 
#' @description
#' generate a random error \eqn{\varepsilon}, which follows one of normal, t and Cauchy distributions.
#' 
#' @param n the number of data points.
#' @param Xdata a list of covariates generated by \code{\link{QM.covariates.generate}}, only used for cases where error.var.type=='heterogeneous'
#' @param tau the quantile of Y given X (default: 0.5).
#' @param error.std a standard deviation parameter for \eqn{\varepsilon}.
#' @param error.var.type a type of error distribution, one of 'homogeneous' or 'heterogeneous'.
#' @param error.type a distribution of \eqn{\varepsilon}, one of 'normal', 't' and 'Cauchy'.
#' @param df degrees of freedom (only used for error.type=='t')
#' 
#' @return an \eqn{n} vector of random errors.
QM.error.generate = function(n,Xdata,tau=0.5,error.std=1,error.var.type='homogeneous',error.type='normal',df=3){
  
  Yspace = 'Euclid'
  Ymu = 0
  
  if (error.var.type=='homogeneous'){
    error.X.std = rep(1,n) * error.std
  } else if (error.var.type=='heterogeneous'){
    Xmu.list = Xdata$Xmu.list
    X = Xdata$X
    Xspaces = X$spaces
    
    idx1 = 1
    idx2 = min(10,X$p)
    error.X.std = 0.5 + 0.5 * pnorm(dist.manifold(Xmu.list[[idx1]],X[[idx1]],Xspaces[idx1])^2) + 0.5 * sin(2*pi*dist.manifold(Xmu.list[[idx2]],X[[idx2]],Xspaces[idx2]))^2
    error.X.std = error.X.std * error.std
  } else{
    stop("The 'error.var.type' must be one of 'homogeneous' or 'heterogeneous'.")
  }
  
  if (error.type=='normal'){
    error = rnorm(n,0,error.X.std)
    error = error - qnorm(tau,0,error.X.std)
  } else if (error.type=='t'){
    error = rt(n,df) * error.X.std
    error = error - qt(tau,df)*error.X.std
  } else if (error.type=='Cauchy'){
    error = rcauchy(n,0,error.X.std)
    error = error - qcauchy(tau,0,error.X.std)
  } else{
    stop("The 'error.type' must be one of 'normal','t' or 'Cauchy'.")
  }
  
  return(matrix(error))
}



############################################################
############################################################
### Generate simulation data for quantile regression


#' @title Generate quantile linear regression data
#' 
#' @description
#' Generate quantile linear regression data.
#' The random error \eqn{\varepsilon} is one of normal, t and Cauchy distributions.
#' The seed for generating Hilbert-Schmidt operators \eqn{\mathfrak{B}_j} is fixed as zero, ensuring that each \eqn{\mathfrak{B}_j} is the same across simulations.
#' 
#' @inheritParams LM.data.generate
#' 
#' @param tau the quantile of Y given X (default: 0.5).
#' @param Ydim the intrinsic dimension of \eqn{Y}, typically 1.
#' @param beta0.norm an integer specifying the norm of \eqn{\beta_0^*}, with a default value of 1.
#' @param c.beta a \eqn{p} vector of pre-computed parameters to ensure that \eqn{\mathbb{E}\| \mathfrak{B_j}(Log_{\mu_j}X_j) \|^2 = (\text{beta.norm[j]})^2}, only computed if not provided.
#' 
#' @return a list of data containing:
#'    \describe{
#'       \item{X}{a list of manifold-valued covariates, see \code{\link{covariates.generate}}.}
#'       \item{Y}{an \eqn{n\times m} matrix of responses.}
#'       \item{p}{the number of \eqn{X_j}.}
#'       \item{link}{a link function, see \code{\link{Check.link}}.}
#'       \item{theta}{an \eqn{n\times m} matrix of canonical parameters for \eqn{Y}.}
#'       \item{Ymu}{an \eqn{n\times m} matrix of the means of \eqn{Y_i}, which is an inverse link of theta.}
#'       \item{beta}{a \eqn{p} list of Hilbert-Schmidt operators, see \code{\link{tensor.beta.generate}}.}
#'       \item{beta0}{a \eqn{m} vector, with \eqn{\|\beta_0^*\| = \text{beta0.norm}}.}
#'       \item{Xmu}{a \eqn{p} list of the Frechet means \eqn{\mu_j} of \eqn{X_j}.}
#'       \item{LogX}{a \eqn{p} list of \eqn{Log_{\mu_j}X_j}, the Riemannian logarithmic transformations of \eqn{X_j}.}
#'       \item{Xbeta.each}{a \eqn{p} list of \eqn{\mathfrak{B}_j(Log_{\mu_j}X_j)}.}
#'       \item{Xbeta}{the sum of Xbeta.each, i.e., \eqn{\sum_{j=1}^p\mathfrak{B}_j(Log_{\mu_j}X_j)}.}
#'       \item{...}{other input parameters.}
#' }
#' @export
QM.data.generate = function(n,Xspaces,Xdims,tau=0.5,proper.indices=NULL,beta.norm=1,beta0.norm=1,Xrho=0.5,Xsigma=1,error.std=1,error.var.type='homogeneous',error.type='normal',df=3,ngrid=100,seed=1,c.beta=NULL){
  
  Yspace = 'Euclid'
  Ydim = 1
  if(is.null(proper.indices)){proper.indices = seq(length(Xdims))}
  if(length(beta.norm)==1){beta.norm = rep(beta.norm,length(Xdims))}
  p = length(Xdims)
  s = length(proper.indices)
  
  # generate Xmu 
  Xmu.list = lapply(1:length(Xdims),function(j){Xmu.generate(Xdims[j],Xspaces[j],ngrid)})
  Ymu = beta0.norm
  
  # generate same beta for each simulation
  set.seed(0)
  n0 = 10000
  beta = tensor.beta.generate(Xspaces,Yspace,Xmu.list,Ymu,Xdims,Ydim,proper.indices,1)
  beta.oracle = lapply(proper.indices,function(j){beta[[j]]})
  
  # generate nuisance X to set |B_j(LogX_j)|=beta.norm[j]
  if (is.null(c.beta)){
    X.base = QM.covariates.generate(n0,Xspaces,Xmu.list,Xdims,Xrho,Xsigma)$X
    LogX.base = lapply(proper.indices,function(j){RieLog.manifold(Xmu.list[[j]],X.base[[j]],Xspaces[j])})
    Xbeta.each.base = lapply(1:s,function(j){operator.tensor(beta.oracle[[j]],LogX.base[[j]])})
    c.beta.tmp = sapply(1:s,function(j){sqrt(mean(norm.manifold(Xbeta.each.base[[j]])^2))})
    c.beta = rep(0,p)
    c.beta[proper.indices] = c.beta.tmp
  }
  
  for (j in proper.indices){
    beta[[j]]$element2 = beta[[j]]$element2 / c.beta[j] * beta.norm[j]
  }
  
  # generate X and error
  set.seed(seed)
  Xdata = QM.covariates.generate(n,Xspaces,Xmu.list,Xdims,Xrho,Xsigma)
  error = QM.error.generate(n,Xdata,tau,error.std,error.var.type,error.type,df)
  
  # compute Xbeta
  X = Xdata$X
  LogX = lapply(1:length(Xdims),function(j){RieLog.manifold(Xmu.list[[j]],X[[j]],Xspaces[j])})
  Xbeta.each = lapply(1:length(Xdims),function(j){operator.tensor(beta[[j]],LogX[[j]])})
  Xbeta = Ymu + Reduce('+',Xbeta.each)
  
  # make Y
  Y = Xbeta + error
  
  data = list(X=X,Y=Y,tau=tau,error.var.type=error.var.type,error.type=error.type,df=df,
              Ymu=Ymu,beta=beta,c.beta=c.beta,error=error,
              Xmu.list=Xmu.list,LogX=LogX,Xbeta=Xbeta,Xbeta.each=Xbeta.each,
              n=n,p=length(Xdims),Xspaces=Xspaces,Xdims=Xdims,Ydim=Ydim,
              proper.indices=proper.indices,beta.norm=beta.norm,beta0.norm=beta0.norm,
              Xrho=Xrho,Xsigma=Xsigma,seed=seed)
  return(data)
}


